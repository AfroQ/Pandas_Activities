{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Day 02\n",
    "# Instructor Turn - 01- Cleaning Data - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Name of the CSV file\n",
    "file = 'Resources/donors2008.csv'\n",
    "\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df = pd.read_csv(file, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>Employer</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Amount</th>\n",
       "      <th>FIELD8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>State Department</td>\n",
       "      <td>Dulles</td>\n",
       "      <td>VA</td>\n",
       "      <td>20189</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abadi</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>Abadi &amp; Co.</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10021</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adamany</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Rockford</td>\n",
       "      <td>IL</td>\n",
       "      <td>61103</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Lorraine</td>\n",
       "      <td>Self</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10026</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Marion</td>\n",
       "      <td>None</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>NH</td>\n",
       "      <td>03833</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LastName FirstName          Employer      City State    Zip  Amount  FIELD8\n",
       "0    Aaron    Eugene  State Department    Dulles    VA  20189   500.0     NaN\n",
       "1    Abadi   Barbara       Abadi & Co.  New York    NY  10021   200.0     NaN\n",
       "2  Adamany   Anthony           Retired  Rockford    IL  61103   500.0     NaN\n",
       "3    Adams  Lorraine              Self  New York    NY  10026   200.0     NaN\n",
       "4    Adams    Marion              None    Exeter    NH  03833   100.0     NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the DataFrame\n",
    "# Note that FIELD8 is likely a meaningless column\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>Employer</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>State Department</td>\n",
       "      <td>Dulles</td>\n",
       "      <td>VA</td>\n",
       "      <td>20189</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abadi</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>Abadi &amp; Co.</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10021</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adamany</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Rockford</td>\n",
       "      <td>IL</td>\n",
       "      <td>61103</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Lorraine</td>\n",
       "      <td>Self</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>10026</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Marion</td>\n",
       "      <td>None</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>NH</td>\n",
       "      <td>03833</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LastName FirstName          Employer      City State    Zip  Amount\n",
       "0    Aaron    Eugene  State Department    Dulles    VA  20189   500.0\n",
       "1    Abadi   Barbara       Abadi & Co.  New York    NY  10021   200.0\n",
       "2  Adamany   Anthony           Retired  Rockford    IL  61103   500.0\n",
       "3    Adams  Lorraine              Self  New York    NY  10026   200.0\n",
       "4    Adams    Marion              None    Exeter    NH  03833   100.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete extraneous column\n",
    "del df['FIELD8']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LastName     1776\n",
       "FirstName    1776\n",
       "Employer     1743\n",
       "City         1776\n",
       "State        1776\n",
       "Zip          1776\n",
       "Amount       1776\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify incomplete rows\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with missing information\n",
    "df = df.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LastName     1743\n",
       "FirstName    1743\n",
       "Employer     1743\n",
       "City         1743\n",
       "State        1743\n",
       "Zip          1743\n",
       "Amount       1743\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify dropped rows\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LastName      object\n",
       "FirstName     object\n",
       "Employer      object\n",
       "City          object\n",
       "State         object\n",
       "Zip           object\n",
       "Amount       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Amount column is the wrong data type. It should be numeric.\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pd.to_numeric() method to convert the datatype of the Amount column\n",
    "df['Amount'] = pd.to_numeric(df['Amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the Amount column datatype has been made numeric\n",
    "df['Amount'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                249\n",
       "Self                                241\n",
       "Retired                             126\n",
       "Self Employed                        39\n",
       "Self-Employed                        34\n",
       "                                   ... \n",
       "Christian Board of Publication        1\n",
       "Kaplan, Strangis, & Kaplan            1\n",
       "Seneca Strategy Partners, Inc.        1\n",
       "Hay Group                             1\n",
       "Eton Park Capital Management LLC      1\n",
       "Name: Employer, Length: 1011, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display an overview of the Employers column\n",
    "df['Employer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Employer category. Replace 'Self Employed' and 'Self' with 'Self-Employed'\n",
    "df['Employer'] = df['Employer'].replace(\n",
    "    {'Self Employed': 'Self-Employed', 'Self': 'Self-Employed'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Self-Employed                       314\n",
       "None                                249\n",
       "Retired                             126\n",
       "Google                                6\n",
       "Not Employed                          4\n",
       "                                   ... \n",
       "Christian Board of Publication        1\n",
       "Kaplan, Strangis, & Kaplan            1\n",
       "Seneca Strategy Partners, Inc.        1\n",
       "Hay Group                             1\n",
       "Eton Park Capital Management LLC      1\n",
       "Name: Employer, Length: 1009, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify clean-up.\n",
    "df['Employer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employer'] = df['Employer'].replace({'Not Employed': 'Unemployed'})\n",
    "df['Employer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a statistical overview\n",
    "# We can infer the maximum allowable individual contribution from 'max'\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn - 02 - Training Grounds - üë©‚Äçüéìüë®‚Äçüéì\n",
    "## Portland Crime\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Read in the csv using Pandas and print out the DataFrame that is returned.\n",
    "\n",
    "* Get a count of rows within the DataFrame in order to determine if there are any null values.\n",
    "\n",
    "* Drop the rows which contain null values.\n",
    "\n",
    "* Search through the \"Offense Type\" column and \"replace\" any similar values with one consistent value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Crime Against</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Occur Date</th>\n",
       "      <th>Occur Month Year</th>\n",
       "      <th>Occur Time</th>\n",
       "      <th>Offense Category</th>\n",
       "      <th>Offense Count</th>\n",
       "      <th>Offense Type</th>\n",
       "      <th>Open Data Lat</th>\n",
       "      <th>Open Data Lon</th>\n",
       "      <th>Open Data X</th>\n",
       "      <th>Open Data Y</th>\n",
       "      <th>Report Date</th>\n",
       "      <th>Report Month Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4762181</td>\n",
       "      <td>Person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/96</td>\n",
       "      <td>1/1/96</td>\n",
       "      <td>800</td>\n",
       "      <td>Sex Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Rape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/26/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4757824</td>\n",
       "      <td>Property</td>\n",
       "      <td>Centennial</td>\n",
       "      <td>1</td>\n",
       "      <td>1/20/00</td>\n",
       "      <td>1/1/00</td>\n",
       "      <td>1615</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/20/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200 BLOCK OF SE 78TH AVE</td>\n",
       "      <td>17-900367</td>\n",
       "      <td>Property</td>\n",
       "      <td>Montavilla</td>\n",
       "      <td>1</td>\n",
       "      <td>12/1/03</td>\n",
       "      <td>12/1/03</td>\n",
       "      <td>800</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>False Pretenses/Swindle/Confidence Game</td>\n",
       "      <td>45.5207</td>\n",
       "      <td>-122.583</td>\n",
       "      <td>7668150.0</td>\n",
       "      <td>682825.0</td>\n",
       "      <td>1/9/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4748982</td>\n",
       "      <td>Property</td>\n",
       "      <td>Southwest Hills</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>0</td>\n",
       "      <td>Fraud Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>Identity Theft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/5/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17-X4748982</td>\n",
       "      <td>Property</td>\n",
       "      <td>Southwest Hills</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>1/1/10</td>\n",
       "      <td>0</td>\n",
       "      <td>Larceny Offenses</td>\n",
       "      <td>1</td>\n",
       "      <td>All Other Larceny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/5/17</td>\n",
       "      <td>1/1/17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Address  Case Number Crime Against     Neighborhood  \\\n",
       "0                       NaN  17-X4762181        Person              NaN   \n",
       "1                       NaN  17-X4757824      Property       Centennial   \n",
       "2  200 BLOCK OF SE 78TH AVE    17-900367      Property       Montavilla   \n",
       "3                       NaN  17-X4748982      Property  Southwest Hills   \n",
       "4                       NaN  17-X4748982      Property  Southwest Hills   \n",
       "\n",
       "   Number of Records Occur Date Occur Month Year  Occur Time  \\\n",
       "0                  1     1/1/96           1/1/96         800   \n",
       "1                  1    1/20/00           1/1/00        1615   \n",
       "2                  1    12/1/03          12/1/03         800   \n",
       "3                  1     1/1/10           1/1/10           0   \n",
       "4                  1     1/1/10           1/1/10           0   \n",
       "\n",
       "   Offense Category  Offense Count                             Offense Type  \\\n",
       "0      Sex Offenses              1                                     Rape   \n",
       "1    Fraud Offenses              1                           Identity Theft   \n",
       "2    Fraud Offenses              1  False Pretenses/Swindle/Confidence Game   \n",
       "3    Fraud Offenses              1                           Identity Theft   \n",
       "4  Larceny Offenses              1                        All Other Larceny   \n",
       "\n",
       "   Open Data Lat  Open Data Lon  Open Data X  Open Data Y Report Date  \\\n",
       "0            NaN            NaN          NaN          NaN     1/26/17   \n",
       "1            NaN            NaN          NaN          NaN     1/20/17   \n",
       "2        45.5207       -122.583    7668150.0     682825.0      1/9/17   \n",
       "3            NaN            NaN          NaN          NaN      1/5/17   \n",
       "4            NaN            NaN          NaN          NaN      1/5/17   \n",
       "\n",
       "  Report Month Year  \n",
       "0            1/1/17  \n",
       "1            1/1/17  \n",
       "2            1/1/17  \n",
       "3            1/1/17  \n",
       "4            1/1/17  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Reference the file where the CSV is located\n",
    "crime_csv_path = \"Resources/crime_incident_data2017.csv\"\n",
    "\n",
    "# Import the data into a Pandas DataFrame\n",
    "crime_df = pd.read_csv(crime_csv_path)\n",
    "crime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              37365\n",
       "Case Number          41032\n",
       "Crime Against        41032\n",
       "Neighborhood         39712\n",
       "Number of Records    41032\n",
       "Occur Date           41032\n",
       "Occur Month Year     41032\n",
       "Occur Time           41032\n",
       "Offense Category     41032\n",
       "Offense Count        41032\n",
       "Offense Type         41032\n",
       "Open Data Lat        36712\n",
       "Open Data Lon        36712\n",
       "Open Data X          36712\n",
       "Open Data Y          36712\n",
       "Report Date          41032\n",
       "Report Month Year    41032\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for missing values\n",
    "crime_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null rows\n",
    "new_crime_df = crime_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address              36146\n",
       "Case Number          36146\n",
       "Crime Against        36146\n",
       "Neighborhood         36146\n",
       "Number of Records    36146\n",
       "Occur Date           36146\n",
       "Occur Month Year     36146\n",
       "Occur Time           36146\n",
       "Offense Category     36146\n",
       "Offense Count        36146\n",
       "Offense Type         36146\n",
       "Open Data Lat        36146\n",
       "Open Data Lon        36146\n",
       "Open Data X          36146\n",
       "Open Data Y          36146\n",
       "Report Date          36146\n",
       "Report Month Year    36146\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify counts\n",
    "new_crime_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Theft From Motor Vehicle                       6947\n",
       "Motor Vehicle Theft                            4689\n",
       "All Other Larceny                              4558\n",
       "Vandalism                                      3863\n",
       "Burglary                                       2824\n",
       "Shoplifting                                    2259\n",
       "Identity Theft                                 1794\n",
       "Simple Assault                                 1216\n",
       "Drug/Narcotic Violations                       1095\n",
       "Theft of Motor Vehicle Parts or Accessories    1073\n",
       "Intimidation                                    900\n",
       "Theft From Building                             895\n",
       "False Pretenses/Swindle/Confidence Game         870\n",
       "Aggravated Assault                              839\n",
       "Robbery                                         608\n",
       "Counterfeiting/Forgery                          448\n",
       "Weapons Law Violations                          266\n",
       "Credit Card/ATM Fraud                           226\n",
       "Arson                                           200\n",
       "Prostitution                                    145\n",
       "Pocket-Picking                                   94\n",
       "Purse-Snatching                                  89\n",
       "Embezzlement                                     73\n",
       "Stolen Property Offenses                         57\n",
       "Kidnapping/Abduction                             22\n",
       "Theft From Coin-Operated Machine or Device       20\n",
       "Hacking/Computer Invasion                        19\n",
       "Animal Cruelty                                   17\n",
       "Pornography/Obscene Material                     10\n",
       "Extortion/Blackmail                               8\n",
       "Assisting or Promoting Prostitution               7\n",
       "Drug Equipment Violations                         6\n",
       "Impersonation                                     4\n",
       "Wire Fraud                                        3\n",
       "Commercial Sex Acts                               1\n",
       "Welfare Fraud                                     1\n",
       "Name: Offense Type, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if there are any values with mispelled or similar values in \"Offense Type\"\n",
    "new_crime_df[\"Offense Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-fa94c76ef7f2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_crime_df['Offense Type'] = new_crime_df['Offense Type'].replace({'Assisting or Promoting Prostitution': 'Prostitution',\n"
     ]
    }
   ],
   "source": [
    "# Combining similar offenses together\n",
    "new_crime_df['Offense Type'] = new_crime_df['Offense Type'].replace({'Assisting or Promoting Prostitution': 'Prostitution', \n",
    "                                                                     'Commercial Sex Acts': 'Prostitution' })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Theft From Motor Vehicle                       6947\n",
       "Motor Vehicle Theft                            4689\n",
       "All Other Larceny                              4558\n",
       "Vandalism                                      3863\n",
       "Burglary                                       2824\n",
       "Shoplifting                                    2259\n",
       "Identity Theft                                 1794\n",
       "Simple Assault                                 1216\n",
       "Drug/Narcotic Violations                       1095\n",
       "Theft of Motor Vehicle Parts or Accessories    1073\n",
       "Intimidation                                    900\n",
       "Theft From Building                             895\n",
       "False Pretenses/Swindle/Confidence Game         870\n",
       "Aggravated Assault                              839\n",
       "Robbery                                         608\n",
       "Counterfeiting/Forgery                          448\n",
       "Weapons Law Violations                          266\n",
       "Credit Card/ATM Fraud                           226\n",
       "Arson                                           200\n",
       "Prostitution                                    153\n",
       "Pocket-Picking                                   94\n",
       "Purse-Snatching                                  89\n",
       "Embezzlement                                     73\n",
       "Stolen Property Offenses                         57\n",
       "Kidnapping/Abduction                             22\n",
       "Theft From Coin-Operated Machine or Device       20\n",
       "Hacking/Computer Invasion                        19\n",
       "Animal Cruelty                                   17\n",
       "Pornography/Obscene Material                     10\n",
       "Extortion/Blackmail                               8\n",
       "Drug Equipment Violations                         6\n",
       "Impersonation                                     4\n",
       "Wire Fraud                                        3\n",
       "Welfare Fraud                                     1\n",
       "Name: Offense Type, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if you comnbined similar offenses correctly in \"Offense Type\".\n",
    "new_crime_df['Offense Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Property    31622\n",
       "Person       2978\n",
       "Society      1546\n",
       "Name: Crime Against, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of crimes against property, society, and person.\n",
    "new_crime_df['Crime Against'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 02 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Reference the file where the CSV is located\n",
    "crime_csv_path = \"Resources/crime_incident_data2017.csv\"\n",
    "\n",
    "# Import the data into a Pandas DataFrame\n",
    "crime_df = pd.read_csv(crime_csv_path)\n",
    "crime_df\n",
    "\n",
    "# look for missing values\n",
    "crime_df.count()\n",
    "\n",
    "# drop null rows\n",
    "no_null_crime_df = crime_df.dropna(how='any')\n",
    "\n",
    "# verify counts\n",
    "no_null_crime_df.count()\n",
    "\n",
    "# Check to see if there are any values with mispelled or similar values in \"Offense Type\"\n",
    "no_null_crime_df[\"Offense Type\"].value_counts()\n",
    "\n",
    "# Combining similar offenses together\n",
    "no_null_crime_df = no_null_crime_df.replace(\n",
    "    {\"Commercial Sex Acts\": \"Prostitution\", \"Assisting or Promoting Prostitution\": \"Prostitution\"})\n",
    "no_null_crime_df\n",
    "\n",
    "# Check to see if you comnbined similar offenses correctly in \"Offense Type\".\n",
    "no_null_crime_df[\"Offense Type\"].value_counts()\n",
    "\n",
    "# Get the number of crimes against property, society, and person.\n",
    "no_null_crime_df[\"Crime Against\"].value_counts()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn - 03 - Loc And Iloc - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Richardson</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Janice</td>\n",
       "      <td>Berry</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "      <td>Asia/Harbin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>Hudson</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>Mcdonald</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "      <td>Europe/Prague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kathy</td>\n",
       "      <td>Morales</td>\n",
       "      <td>351-(720)541-2124</td>\n",
       "      <td>Europe/Lisbon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name   last_name       Phone Number      Time zone\n",
       "0   1      Peter  Richardson    7-(789)867-9023  Europe/Moscow\n",
       "1   2     Janice       Berry   86-(614)973-1727    Asia/Harbin\n",
       "2   3     Andrea      Hudson   86-(918)527-6371  Asia/Shanghai\n",
       "3   4     Arthur    Mcdonald  420-(553)779-7783  Europe/Prague\n",
       "4   5      Kathy     Morales  351-(720)541-2124  Europe/Lisbon"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"Resources/sampleData.csv\"\n",
    "\n",
    "original_df = pd.read_csv(file)\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry</th>\n",
       "      <td>2</td>\n",
       "      <td>Janice</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "      <td>Asia/Harbin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mcdonald</th>\n",
       "      <td>4</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "      <td>Europe/Prague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morales</th>\n",
       "      <td>5</td>\n",
       "      <td>Kathy</td>\n",
       "      <td>351-(720)541-2124</td>\n",
       "      <td>Europe/Lisbon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id first_name       Phone Number      Time zone\n",
       "last_name                                                  \n",
       "Richardson   1      Peter    7-(789)867-9023  Europe/Moscow\n",
       "Berry        2     Janice   86-(614)973-1727    Asia/Harbin\n",
       "Hudson       3     Andrea   86-(918)527-6371  Asia/Shanghai\n",
       "Mcdonald     4     Arthur  420-(553)779-7783  Europe/Prague\n",
       "Morales      5      Kathy  351-(720)541-2124  Europe/Lisbon"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set new index to last_name\n",
    "df = original_df.set_index(\"last_name\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Loc: 86-(614)973-1727\n"
     ]
    }
   ],
   "source": [
    "# Grab the data contained within the \"Berry\" row and the \"Phone Number\" column\n",
    "berry_phone = df.loc[\"Berry\", \"Phone Number\"]\n",
    "print(\"Using Loc: \" + berry_phone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Iloc: 86-(614)973-1727\n"
     ]
    }
   ],
   "source": [
    "also_berry_phone = df.iloc[1, 2]\n",
    "print(\"Using Iloc: \" + also_berry_phone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first five rows of data and the columns from \"id\" to \"Phone Number\"\n",
    "# The problem with using \"last_name\" as the index is that the values are not unique so duplicates are returned\n",
    "# If there are duplicates and loc[] is being used, Pandas will return an error\n",
    "richardson_to_morales = df.loc[[\"Richardson\", \"Berry\", \"Hudson\",\n",
    "                                \"Mcdonald\", \"Morales\"], [\"id\", \"first_name\", \"Phone Number\"]]\n",
    "richardson_to_morales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry</th>\n",
       "      <td>2</td>\n",
       "      <td>Janice</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>3</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mcdonald</th>\n",
       "      <td>4</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id first_name       Phone Number\n",
       "last_name                                   \n",
       "Richardson   1      Peter    7-(789)867-9023\n",
       "Berry        2     Janice   86-(614)973-1727\n",
       "Hudson       3     Andrea   86-(918)527-6371\n",
       "Mcdonald     4     Arthur  420-(553)779-7783"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using iloc[] will not find duplicates since a numeric index is always unique\n",
    "also_richardson_to_morales = df.iloc[0:4, 0:3]\n",
    "also_richardson_to_morales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry</th>\n",
       "      <td>Janice</td>\n",
       "      <td>86-(614)973-1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hudson</th>\n",
       "      <td>Andrea</td>\n",
       "      <td>86-(918)527-6371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mcdonald</th>\n",
       "      <td>Arthur</td>\n",
       "      <td>420-(553)779-7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morales</th>\n",
       "      <td>Kathy</td>\n",
       "      <td>351-(720)541-2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           first_name       Phone Number\n",
       "last_name                               \n",
       "Richardson      Peter    7-(789)867-9023\n",
       "Berry          Janice   86-(614)973-1727\n",
       "Hudson         Andrea   86-(918)527-6371\n",
       "Mcdonald       Arthur  420-(553)779-7783\n",
       "Morales         Kathy  351-(720)541-2124"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following will select all rows for columns `first_name` and `Phone Number`\n",
    "df.loc[:, [\"first_name\", \"Phone Number\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_name\n",
       "Richardson    False\n",
       "Berry         False\n",
       "Hudson        False\n",
       "Mcdonald      False\n",
       "Morales       False\n",
       "Name: first_name, dtype: bool"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following logic test/conditional statement returns a series of boolean values\n",
    "named_billy = df[\"first_name\"] == \"Billy\"\n",
    "named_billy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clark</th>\n",
       "      <td>20</td>\n",
       "      <td>Billy</td>\n",
       "      <td>62-(213)345-2549</td>\n",
       "      <td>Asia/Makassar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrews</th>\n",
       "      <td>23</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(859)746-5367</td>\n",
       "      <td>Asia/Chongqing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>59</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(878)547-7739</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id first_name      Phone Number       Time zone\n",
       "last_name                                                 \n",
       "Clark      20      Billy  62-(213)345-2549   Asia/Makassar\n",
       "Andrews    23      Billy  86-(859)746-5367  Asia/Chongqing\n",
       "Price      59      Billy  86-(878)547-7739   Asia/Shanghai"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loc and Iloc also allow for conditional statments to filter rows of data\n",
    "# using Loc on the logic test above only returns rows where the result is True\n",
    "only_billys = df.loc[df[\"first_name\"] == \"Billy\", :]\n",
    "only_billys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Time zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Richardson</th>\n",
       "      <td>1</td>\n",
       "      <td>Peter</td>\n",
       "      <td>7-(789)867-9023</td>\n",
       "      <td>Europe/Moscow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clark</th>\n",
       "      <td>20</td>\n",
       "      <td>Billy</td>\n",
       "      <td>62-(213)345-2549</td>\n",
       "      <td>Asia/Makassar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrews</th>\n",
       "      <td>23</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(859)746-5367</td>\n",
       "      <td>Asia/Chongqing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>59</td>\n",
       "      <td>Billy</td>\n",
       "      <td>86-(878)547-7739</td>\n",
       "      <td>Asia/Shanghai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id first_name      Phone Number       Time zone\n",
       "last_name                                                  \n",
       "Richardson   1      Peter   7-(789)867-9023   Europe/Moscow\n",
       "Clark       20      Billy  62-(213)345-2549   Asia/Makassar\n",
       "Andrews     23      Billy  86-(859)746-5367  Asia/Chongqing\n",
       "Price       59      Billy  86-(878)547-7739   Asia/Shanghai"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple conditions can be set to narrow down or widen the filter\n",
    "only_billy_and_peter = df.loc[(df[\"first_name\"] == \"Billy\") | (\n",
    "    df[\"first_name\"] == \"Peter\"), :]\n",
    "\n",
    "only_billy_and_peter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students Turn - 04 - Good Movies - üë©‚Äçüéìüë®‚Äçüéì\n",
    "## Good Movies\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Use Pandas to load and display the CSV provided in `Resources`.\n",
    "\n",
    "* List all the columns in the data set.\n",
    "\n",
    "* We're only interested in IMDb data, so create a new table that takes the Film and all the columns relating to IMDB.\n",
    "\n",
    "* Filter out only the good movies‚Äîi.e., any film with an IMDb score greater than or equal to 7 and remove the norm ratings.\n",
    "\n",
    "* Find less popular movies that you may not have heard about - i.e., anything with under 20K votes\n",
    "\n",
    "Data Source:[Moving Rating Dataset](https://github.com/fivethirtyeight/data/blob/master/fandango/fandango_score_comparison.csv)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencie\n",
    "import pandas as pd\n",
    "\n",
    "# Load in file\n",
    "movie_file = \"Resources/movie_scores.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILM</th>\n",
       "      <th>RottenTomatoes</th>\n",
       "      <th>RottenTomatoes_User</th>\n",
       "      <th>Metacritic</th>\n",
       "      <th>Metacritic_User</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>Fandango_Stars</th>\n",
       "      <th>Fandango_Ratingvalue</th>\n",
       "      <th>RT_norm</th>\n",
       "      <th>RT_user_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>IMDB_norm</th>\n",
       "      <th>RT_norm_round</th>\n",
       "      <th>RT_user_norm_round</th>\n",
       "      <th>Metacritic_norm_round</th>\n",
       "      <th>Metacritic_user_norm_round</th>\n",
       "      <th>IMDB_norm_round</th>\n",
       "      <th>Metacritic_user_vote_count</th>\n",
       "      <th>IMDB_user_vote_count</th>\n",
       "      <th>Fandango_votes</th>\n",
       "      <th>Fandango_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avengers: Age of Ultron (2015)</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1330</td>\n",
       "      <td>271107</td>\n",
       "      <td>14846</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinderella (2015)</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>249</td>\n",
       "      <td>65709</td>\n",
       "      <td>12640</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ant-Man (2015)</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>627</td>\n",
       "      <td>103660</td>\n",
       "      <td>12055</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do You Believe? (2015)</td>\n",
       "      <td>18</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>31</td>\n",
       "      <td>3136</td>\n",
       "      <td>1793</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hot Tub Time Machine 2 (2015)</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>88</td>\n",
       "      <td>19560</td>\n",
       "      <td>1021</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             FILM  RottenTomatoes  RottenTomatoes_User  \\\n",
       "0  Avengers: Age of Ultron (2015)              74                   86   \n",
       "1               Cinderella (2015)              85                   80   \n",
       "2                  Ant-Man (2015)              80                   90   \n",
       "3          Do You Believe? (2015)              18                   84   \n",
       "4   Hot Tub Time Machine 2 (2015)              14                   28   \n",
       "\n",
       "   Metacritic  Metacritic_User  IMDB  Fandango_Stars  Fandango_Ratingvalue  \\\n",
       "0          66              7.1   7.8             5.0                   4.5   \n",
       "1          67              7.5   7.1             5.0                   4.5   \n",
       "2          64              8.1   7.8             5.0                   4.5   \n",
       "3          22              4.7   5.4             5.0                   4.5   \n",
       "4          29              3.4   5.1             3.5                   3.0   \n",
       "\n",
       "   RT_norm  RT_user_norm  ...  IMDB_norm  RT_norm_round  RT_user_norm_round  \\\n",
       "0     3.70           4.3  ...       3.90            3.5                 4.5   \n",
       "1     4.25           4.0  ...       3.55            4.5                 4.0   \n",
       "2     4.00           4.5  ...       3.90            4.0                 4.5   \n",
       "3     0.90           4.2  ...       2.70            1.0                 4.0   \n",
       "4     0.70           1.4  ...       2.55            0.5                 1.5   \n",
       "\n",
       "   Metacritic_norm_round  Metacritic_user_norm_round  IMDB_norm_round  \\\n",
       "0                    3.5                         3.5              4.0   \n",
       "1                    3.5                         4.0              3.5   \n",
       "2                    3.0                         4.0              4.0   \n",
       "3                    1.0                         2.5              2.5   \n",
       "4                    1.5                         1.5              2.5   \n",
       "\n",
       "   Metacritic_user_vote_count  IMDB_user_vote_count  Fandango_votes  \\\n",
       "0                        1330                271107           14846   \n",
       "1                         249                 65709           12640   \n",
       "2                         627                103660           12055   \n",
       "3                          31                  3136            1793   \n",
       "4                          88                 19560            1021   \n",
       "\n",
       "   Fandango_Difference  \n",
       "0                  0.5  \n",
       "1                  0.5  \n",
       "2                  0.5  \n",
       "3                  0.5  \n",
       "4                  0.5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read and display the CSV with Pandas\n",
    "movie_file_df = pd.read_csv(movie_file)\n",
    "movie_file_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FILM', 'RottenTomatoes', 'RottenTomatoes_User', 'Metacritic',\n",
       "       'Metacritic_User', 'IMDB', 'Fandango_Stars', 'Fandango_Ratingvalue',\n",
       "       'RT_norm', 'RT_user_norm', 'Metacritic_norm', 'Metacritic_user_nom',\n",
       "       'IMDB_norm', 'RT_norm_round', 'RT_user_norm_round',\n",
       "       'Metacritic_norm_round', 'Metacritic_user_norm_round',\n",
       "       'IMDB_norm_round', 'Metacritic_user_vote_count', 'IMDB_user_vote_count',\n",
       "       'Fandango_votes', 'Fandango_Difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all the columns in the table\n",
    "movie_file_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want IMDb data, so create a new table that takes the Film \n",
    "# and all the columns relating to IMDB\n",
    "imdb_df = movie_file_df[[\"FILM\", \"IMDB\", \"IMDB_norm\",\n",
    "                            \"IMDB_norm_round\", \"IMDB_user_vote_count\"]]\n",
    "imdb_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only like good movies, so find those that scored over 7, and ignore the norm rating\n",
    "\n",
    "good_movies_df = movie_file_df.loc[movie_file_df[\"IMDB\"] > 7, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "good_movies_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find less popular movies--i.e., those with fewer than 20K votes\n",
    "unknown_movies_df = good_movies_df.loc[good_movies_df[\"IMDB_user_vote_count\"] < 20000, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "unknown_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 04 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "# Dependencie\n",
    "import pandas as pd\n",
    "\n",
    "# Load in file\n",
    "movie_file = \"Resources/movie_scores.csv\"\n",
    "\n",
    "# Read and display the CSV with Pandas\n",
    "movie_file_df = pd.read_csv(movie_file)\n",
    "movie_file_df.head()\n",
    "\n",
    "# List all the columns in the table\n",
    "movie_file_df.columns\n",
    "\n",
    "\n",
    "# We only want IMDb data, so create a new table that takes the Film and all the columns relating to IMDB\n",
    "imdb_df = movie_file_df[[\"FILM\", \"IMDB\", \"IMDB_norm\",\n",
    "                            \"IMDB_norm_round\", \"IMDB_user_vote_count\"]]\n",
    "imdb_df.head()\n",
    "\n",
    "# We only like good movies, so find those that scored over 7, and ignore the norm rating\n",
    "good_movies_df = movie_file_df.loc[movie_file_df[\"IMDB\"] > 7, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "good_movies_df.head()\n",
    "\n",
    "# Find less popular movies--i.e., those with fewer than 20K votes\n",
    "unknown_movies_df = good_movies_df.loc[good_movies_df[\"IMDB_user_vote_count\"] < 20000, [\n",
    "    \"FILM\", \"IMDB\", \"IMDB_user_vote_count\"]]\n",
    "unknown_movies_df.head()\n",
    "\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn - 05 - GroupBy - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>12/16/2005</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>1/21/2008</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime                  city state country     shape  \\\n",
       "0  10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
       "1  10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
       "2  10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  10/10/1956 21:00                  edna    tx      us    circle   \n",
       "4  10/10/1960 20:00               kaneohe    hi      us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...   4/27/2004  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...   1/21/2008        53.2   \n",
       "3  My older brother and twin sister were leaving ...   1/17/2004  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004  21.4180556   \n",
       "\n",
       "   longitude   \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Create a reference the CSV file desired\n",
    "csv_path = \"Resources/ufoSightings.csv\"\n",
    "\n",
    "# Read the CSV into a Pandas DataFrame\n",
    "ufo_df = pd.read_csv(csv_path, low_memory = False)\n",
    "\n",
    "# Print the first five rows of data to the screen\n",
    "ufo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                66516\n",
       "city                    66516\n",
       "state                   66516\n",
       "country                 66516\n",
       "shape                   66516\n",
       "duration (seconds)      66516\n",
       "duration (hours/min)    66516\n",
       "comments                66516\n",
       "date posted             66516\n",
       "latitude                66516\n",
       "longitude               66516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the rows with missing data\n",
    "clean_ufo_df = ufo_df.dropna(how=\"any\")\n",
    "clean_ufo_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 object\n",
       "city                     object\n",
       "state                    object\n",
       "country                  object\n",
       "shape                    object\n",
       "duration (seconds)       object\n",
       "duration (hours/min)     object\n",
       "comments                 object\n",
       "date posted              object\n",
       "latitude                 object\n",
       "longitude               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ufo_df.head()\n",
    "clean_ufo_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900.0</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/10/1961 19:00</td>\n",
       "      <td>bristol</td>\n",
       "      <td>tn</td>\n",
       "      <td>us</td>\n",
       "      <td>sphere</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>My father is now 89 my brother 52 the girl wit...</td>\n",
       "      <td>4/27/2007</td>\n",
       "      <td>36.595</td>\n",
       "      <td>-82.188889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/10/1965 23:45</td>\n",
       "      <td>norwalk</td>\n",
       "      <td>ct</td>\n",
       "      <td>us</td>\n",
       "      <td>disk</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>A bright orange color changing to reddish colo...</td>\n",
       "      <td>10/2/1999</td>\n",
       "      <td>41.1175</td>\n",
       "      <td>-73.408333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime        city state country     shape  duration (seconds)  \\\n",
       "0  10/10/1949 20:30  san marcos    tx      us  cylinder              2700.0   \n",
       "3  10/10/1956 21:00        edna    tx      us    circle                20.0   \n",
       "4  10/10/1960 20:00     kaneohe    hi      us     light               900.0   \n",
       "5  10/10/1961 19:00     bristol    tn      us    sphere               300.0   \n",
       "7  10/10/1965 23:45     norwalk    ct      us      disk              1200.0   \n",
       "\n",
       "  duration (hours/min)                                           comments  \\\n",
       "0           45 minutes  This event took place in early fall around 194...   \n",
       "3             1/2 hour  My older brother and twin sister were leaving ...   \n",
       "4           15 minutes  AS a Marine 1st Lt. flying an FJ4B fighter/att...   \n",
       "5            5 minutes  My father is now 89 my brother 52 the girl wit...   \n",
       "7           20 minutes  A bright orange color changing to reddish colo...   \n",
       "\n",
       "  date posted    latitude  longitude   \n",
       "0   4/27/2004  29.8830556  -97.941111  \n",
       "3   1/17/2004  28.9783333  -96.645833  \n",
       "4   1/22/2004  21.4180556 -157.803611  \n",
       "5   4/27/2007      36.595  -82.188889  \n",
       "7   10/2/1999     41.1175  -73.408333  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the \"duration (seconds)\" column's values to numeric\n",
    "converted_ufo = clean_ufo_df.copy()\n",
    "converted_ufo[\"duration (seconds)\"] = converted_ufo.loc[:, \"duration (seconds)\"].astype(float)\n",
    "\n",
    "converted_ufo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                 object\n",
       "city                     object\n",
       "state                    object\n",
       "country                  object\n",
       "shape                    object\n",
       "duration (seconds)      float64\n",
       "duration (hours/min)     object\n",
       "comments                 object\n",
       "date posted              object\n",
       "latitude                 object\n",
       "longitude               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900.0</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/10/1961 19:00</td>\n",
       "      <td>bristol</td>\n",
       "      <td>tn</td>\n",
       "      <td>us</td>\n",
       "      <td>sphere</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>My father is now 89 my brother 52 the girl wit...</td>\n",
       "      <td>4/27/2007</td>\n",
       "      <td>36.595</td>\n",
       "      <td>-82.188889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/10/1965 23:45</td>\n",
       "      <td>norwalk</td>\n",
       "      <td>ct</td>\n",
       "      <td>us</td>\n",
       "      <td>disk</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>20 minutes</td>\n",
       "      <td>A bright orange color changing to reddish colo...</td>\n",
       "      <td>10/2/1999</td>\n",
       "      <td>41.1175</td>\n",
       "      <td>-73.408333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           datetime        city state country     shape  duration (seconds)  \\\n",
       "0  10/10/1949 20:30  san marcos    tx      us  cylinder              2700.0   \n",
       "3  10/10/1956 21:00        edna    tx      us    circle                20.0   \n",
       "4  10/10/1960 20:00     kaneohe    hi      us     light               900.0   \n",
       "5  10/10/1961 19:00     bristol    tn      us    sphere               300.0   \n",
       "7  10/10/1965 23:45     norwalk    ct      us      disk              1200.0   \n",
       "\n",
       "  duration (hours/min)                                           comments  \\\n",
       "0           45 minutes  This event took place in early fall around 194...   \n",
       "3             1/2 hour  My older brother and twin sister were leaving ...   \n",
       "4           15 minutes  AS a Marine 1st Lt. flying an FJ4B fighter/att...   \n",
       "5            5 minutes  My father is now 89 my brother 52 the girl wit...   \n",
       "7           20 minutes  A bright orange color changing to reddish colo...   \n",
       "\n",
       "  date posted    latitude  longitude   \n",
       "0   4/27/2004  29.8830556  -97.941111  \n",
       "3   1/17/2004  28.9783333  -96.645833  \n",
       "4   1/22/2004  21.4180556 -157.803611  \n",
       "5   4/27/2007      36.595  -82.188889  \n",
       "7   10/2/1999     41.1175  -73.408333  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data so that only those sightings in the US are in a DataFrame\n",
    "usa_ufo_df = converted_ufo.loc[converted_ufo[\"country\"] == \"us\", :]\n",
    "usa_ufo_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca    8683\n",
       "fl    3754\n",
       "wa    3707\n",
       "tx    3398\n",
       "ny    2915\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many sightings have occured within each state\n",
    "state_counts = usa_ufo_df[\"state\"].value_counts()\n",
    "state_counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000299A8667370>\n"
     ]
    }
   ],
   "source": [
    "# Using GroupBy in order to separate the data into fields according to \"state\" values\n",
    "grouped_usa_df = usa_ufo_df.groupby(['state'])\n",
    "\n",
    "# The object returned is a \"GroupBy\" object and cannot be viewed normally...\n",
    "print(grouped_usa_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "ak     1455863.00\n",
       "al      900453.50\n",
       "ar    66986144.50\n",
       "az    15453494.60\n",
       "ca    24865571.47\n",
       "co     1923709.00\n",
       "ct     3110318.80\n",
       "dc        1645.50\n",
       "de      142969.50\n",
       "fl    55900005.00\n",
       "ga     9519878.10\n",
       "hi     6732485.00\n",
       "ia      613576.00\n",
       "id      475270.30\n",
       "il     2133923.07\n",
       "in     4032395.70\n",
       "ks      830518.50\n",
       "ky     3435497.50\n",
       "la     6819072.00\n",
       "ma     1602861.00\n",
       "md      688074.30\n",
       "me      654476.90\n",
       "mi     1895119.10\n",
       "mn     1382802.33\n",
       "mo     1614738.80\n",
       "ms     3396695.00\n",
       "mt     1050599.00\n",
       "nc     2056718.35\n",
       "nd      140274.00\n",
       "ne      412354.00\n",
       "nh     1072798.50\n",
       "nj     7784974.00\n",
       "nm     4055283.59\n",
       "nv     2393413.95\n",
       "ny     8898149.55\n",
       "oh     3284932.80\n",
       "ok      853112.30\n",
       "or     1774625.28\n",
       "pa     9110355.00\n",
       "pr       26200.00\n",
       "ri      472900.50\n",
       "sc     1089566.80\n",
       "sd      480358.50\n",
       "tn     1854526.30\n",
       "tx     8444239.25\n",
       "ut     3417964.00\n",
       "va    13606781.00\n",
       "vt      264785.50\n",
       "wa    56618769.44\n",
       "wi     2323749.30\n",
       "wv     2974853.00\n",
       "wy      251443.00\n",
       "Name: duration (seconds), dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to be visualized, a data function must be used...\n",
    "grouped_usa_df.count().head(10)\n",
    "\n",
    "grouped_usa_df[\"duration (seconds)\"].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since \"duration (seconds)\" was converted to a numeric time, it can now be summed up per state\n",
    "state_duration = grouped_usa_df[\"duration (seconds)\"].sum()\n",
    "state_duration.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame using both duration and count\n",
    "state_summary_table = pd.DataFrame({\"Number of Sightings\": state_counts,\n",
    "                                    \"Total Visit Time\": state_duration})\n",
    "state_summary_table.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also possible to group a DataFrame by multiple columns\n",
    "# This returns an object with multiple indexes, however, which can be harder to deal with\n",
    "grouped_international_data = converted_ufo.groupby(['country', 'state'])\n",
    "\n",
    "grouped_international_data.count().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting a GroupBy object into a DataFrame\n",
    "international_duration = pd.DataFrame(\n",
    "    grouped_international_data[\"duration (seconds)\"].sum())\n",
    "international_duration.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Turn - 06 - Training Grounds - üë©‚Äçüéìüë®‚Äçüéì\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Using the DataFrame provided, do the following:\n",
    "\n",
    "    * Convert the \"Membership (Days)\" column into weeks and then add this new series into the DataFrame\n",
    "\n",
    "    * Create a Dataframe that has only the \"Trainer\", \"Weight\", and membership in days and weeks.\n",
    "\n",
    "    * Using groupby get the average weight and length membership of the gym members for each trainer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Trainer</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Membership (Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gino Walker</td>\n",
       "      <td>Bettyann Savory</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiedi Wasser</td>\n",
       "      <td>Mariah Barberio</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerrie Wetzel</td>\n",
       "      <td>Gordon Perrine</td>\n",
       "      <td>193</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elizabeth Sackett</td>\n",
       "      <td>Pa Dargan</td>\n",
       "      <td>177</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack Mitten</td>\n",
       "      <td>Blanch Victoria</td>\n",
       "      <td>237</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name          Trainer  Weight  Membership (Days)\n",
       "0        Gino Walker  Bettyann Savory     128                 52\n",
       "1       Hiedi Wasser  Mariah Barberio     180                 70\n",
       "2      Kerrie Wetzel   Gordon Perrine     193                148\n",
       "3  Elizabeth Sackett        Pa Dargan     177                124\n",
       "4        Jack Mitten  Blanch Victoria     237                186"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members\n",
    "training_data = pd.DataFrame({\n",
    "    \"Name\":[\"Gino Walker\",\"Hiedi Wasser\",\"Kerrie Wetzel\",\"Elizabeth Sackett\",\"Jack Mitten\",\"Madalene Wayman\",\"Jamee Horvath\",\"Arlena Reddin\",\"Tula Levan\",\"Teisha Dreier\",\"Leslie Carrier\",\"Arlette Hartson\",\"Romana Merkle\",\"Heath Viviani\",\"Andres Zimmer\",\"Allyson Osman\",\"Yadira Caggiano\",\"Jeanmarie Friedrichs\",\"Leann Ussery\",\"Bee Mom\",\"Pandora Charland\",\"Karena Wooten\",\"Elizabet Albanese\",\"Augusta Borjas\",\"Erma Yadon\",\"Belia Lenser\",\"Karmen Sancho\",\"Edison Mannion\",\"Sonja Hornsby\",\"Morgan Frei\",\"Florencio Murphy\",\"Christoper Hertel\",\"Thalia Stepney\",\"Tarah Argento\",\"Nicol Canfield\",\"Pok Moretti\",\"Barbera Stallings\",\"Muoi Kelso\",\"Cicely Ritz\",\"Sid Demelo\",\"Eura Langan\",\"Vanita An\",\"Frieda Fuhr\",\"Ernest Fitzhenry\",\"Ashlyn Tash\",\"Melodi Mclendon\",\"Rochell Leblanc\",\"Jacqui Reasons\",\"Freeda Mccroy\",\"Vanna Runk\",\"Florinda Milot\",\"Cierra Lecompte\",\"Nancey Kysar\",\"Latasha Dalton\",\"Charlyn Rinaldi\",\"Erline Averett\",\"Mariko Hillary\",\"Rosalyn Trigg\",\"Sherwood Brauer\",\"Hortencia Olesen\",\"Delana Kohut\",\"Geoffrey Mcdade\",\"Iona Delancey\",\"Donnie Read\",\"Cesar Bhatia\",\"Evia Slate\",\"Kaye Hugo\",\"Denise Vento\",\"Lang Kittle\",\"Sherry Whittenberg\",\"Jodi Bracero\",\"Tamera Linneman\",\"Katheryn Koelling\",\"Tonia Shorty\",\"Misha Baxley\",\"Lisbeth Goering\",\"Merle Ladwig\",\"Tammie Omar\",\"Jesusa Avilla\",\"Alda Zabala\",\"Junita Dogan\",\"Jessia Anglin\",\"Peggie Scranton\",\"Dania Clodfelter\",\"Janis Mccarthy\",\"Edmund Galusha\",\"Tonisha Posey\",\"Arvilla Medley\",\"Briana Barbour\",\"Delfina Kiger\",\"Nia Lenig\",\"Ricarda Bulow\",\"Odell Carson\",\"Nydia Clonts\",\"Andree Resendez\",\"Daniela Puma\",\"Sherill Paavola\",\"Gilbert Bloomquist\",\"Shanon Mach\",\"Justin Bangert\",\"Arden Hokanson\",\"Evelyne Bridge\",\"Hee Simek\",\"Ward Deangelis\",\"Jodie Childs\",\"Janis Boehme\",\"Beaulah Glowacki\",\"Denver Stoneham\",\"Tarra Vinton\",\"Deborah Hummell\",\"Ulysses Neil\",\"Kathryn Marques\",\"Rosanna Dake\",\"Gavin Wheat\",\"Tameka Stoke\",\"Janella Clear\",\"Kaye Ciriaco\",\"Suk Bloxham\",\"Gracia Whaley\",\"Philomena Hemingway\",\"Claudette Vaillancourt\",\"Olevia Piche\",\"Trey Chiles\",\"Idalia Scardina\",\"Jenine Tremble\",\"Herbert Krider\",\"Alycia Schrock\",\"Miss Weibel\",\"Pearlene Neidert\",\"Kina Callender\",\"Charlotte Skelley\",\"Theodora Harrigan\",\"Sydney Shreffler\",\"Annamae Trinidad\",\"Tobi Mumme\",\"Rosia Elliot\",\"Debbra Putt\",\"Rena Delosantos\",\"Genna Grennan\",\"Nieves Huf\",\"Berry Lugo\",\"Ayana Verdugo\",\"Joaquin Mazzei\",\"Doris Harmon\",\"Patience Poss\",\"Magaret Zabel\",\"Marylynn Hinojos\",\"Earlene Marcantel\",\"Yuki Evensen\",\"Rema Gay\",\"Delana Haak\",\"Patricia Fetters\",\"Vinnie Elrod\",\"Octavia Bellew\",\"Burma Revard\",\"Lakenya Kato\",\"Vinita Buchner\",\"Sierra Margulies\",\"Shae Funderburg\",\"Jenae Groleau\",\"Louetta Howie\",\"Astrid Duffer\",\"Caron Altizer\",\"Kymberly Amavisca\",\"Mohammad Diedrich\",\"Thora Wrinkle\",\"Bethel Wiemann\",\"Patria Millet\",\"Eldridge Burbach\",\"Alyson Eddie\",\"Zula Hanna\",\"Devin Goodwin\",\"Felipa Kirkwood\",\"Kurtis Kempf\",\"Kasey Lenart\",\"Deena Blankenship\",\"Kandra Wargo\",\"Sherrie Cieslak\",\"Ron Atha\",\"Reggie Barreiro\",\"Daria Saulter\",\"Tandra Eastman\",\"Donnell Lucious\",\"Talisha Rosner\",\"Emiko Bergh\",\"Terresa Launius\",\"Margy Hoobler\",\"Marylou Stelling\",\"Lavonne Justice\",\"Kala Langstaff\",\"China Truett\",\"Louanne Dussault\",\"Thomasena Samaniego\",\"Charlesetta Tarbell\",\"Fatimah Lade\",\"Malisa Cantero\",\"Florencia Litten\",\"Francina Fraise\",\"Patsy London\",\"Deloris Mclaughlin\"],\n",
    "    \"Trainer\":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],\n",
    "    \"Weight\":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],\n",
    "    \"Membership (Days)\":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]\n",
    "})\n",
    "training_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Trainer</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Membership (Days)</th>\n",
       "      <th>Membership (Weeks)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gino Walker</td>\n",
       "      <td>Bettyann Savory</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "      <td>7.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiedi Wasser</td>\n",
       "      <td>Mariah Barberio</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerrie Wetzel</td>\n",
       "      <td>Gordon Perrine</td>\n",
       "      <td>193</td>\n",
       "      <td>148</td>\n",
       "      <td>21.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elizabeth Sackett</td>\n",
       "      <td>Pa Dargan</td>\n",
       "      <td>177</td>\n",
       "      <td>124</td>\n",
       "      <td>17.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack Mitten</td>\n",
       "      <td>Blanch Victoria</td>\n",
       "      <td>237</td>\n",
       "      <td>186</td>\n",
       "      <td>26.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name          Trainer  Weight  Membership (Days)  \\\n",
       "0        Gino Walker  Bettyann Savory     128                 52   \n",
       "1       Hiedi Wasser  Mariah Barberio     180                 70   \n",
       "2      Kerrie Wetzel   Gordon Perrine     193                148   \n",
       "3  Elizabeth Sackett        Pa Dargan     177                124   \n",
       "4        Jack Mitten  Blanch Victoria     237                186   \n",
       "\n",
       "   Membership (Weeks)  \n",
       "0            7.428571  \n",
       "1           10.000000  \n",
       "2           21.142857  \n",
       "3           17.714286  \n",
       "4           26.571429  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the membership days into weeks and then add a this data in a new column to the DataFrame.\n",
    "weeks = training_data[\"Membership (Days)\"]/7\n",
    "training_data[\"Membership (Weeks)\"] = weeks\n",
    "training_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trainer</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Membership (Days)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bettyann Savory</td>\n",
       "      <td>128</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mariah Barberio</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Perrine</td>\n",
       "      <td>193</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pa Dargan</td>\n",
       "      <td>177</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blanch Victoria</td>\n",
       "      <td>237</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Trainer  Weight  Membership (Days)\n",
       "0  Bettyann Savory     128                 52\n",
       "1  Mariah Barberio     180                 70\n",
       "2   Gordon Perrine     193                148\n",
       "3        Pa Dargan     177                124\n",
       "4  Blanch Victoria     237                186"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Dataframe that has the Trainer, Weight, and Membership.\n",
    "new_training_df = training_data[[\"Trainer\", \"Weight\", \"Membership (Days)\"]]\n",
    "new_training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Membership (Days)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trainer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aldo Byler</th>\n",
       "      <td>183.000000</td>\n",
       "      <td>103.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barton Stecklein</th>\n",
       "      <td>174.384615</td>\n",
       "      <td>81.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bettyann Savory</th>\n",
       "      <td>179.200000</td>\n",
       "      <td>102.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blanch Victoria</th>\n",
       "      <td>189.571429</td>\n",
       "      <td>101.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brittani Brin</th>\n",
       "      <td>182.875000</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calvin North</th>\n",
       "      <td>158.571429</td>\n",
       "      <td>99.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coleman Dunmire</th>\n",
       "      <td>194.411765</td>\n",
       "      <td>98.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gordon Perrine</th>\n",
       "      <td>185.142857</td>\n",
       "      <td>106.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harland Coolidge</th>\n",
       "      <td>182.750000</td>\n",
       "      <td>106.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junie Ritenour</th>\n",
       "      <td>179.571429</td>\n",
       "      <td>86.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mariah Barberio</th>\n",
       "      <td>170.866667</td>\n",
       "      <td>110.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa Dargan</th>\n",
       "      <td>186.071429</td>\n",
       "      <td>108.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phyliss Houk</th>\n",
       "      <td>174.000000</td>\n",
       "      <td>98.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williams Camire</th>\n",
       "      <td>177.818182</td>\n",
       "      <td>111.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Weight  Membership (Days)\n",
       "Trainer                                        \n",
       "Aldo Byler        183.000000         103.529412\n",
       "Barton Stecklein  174.384615          81.153846\n",
       "Bettyann Savory   179.200000         102.350000\n",
       "Blanch Victoria   189.571429         101.071429\n",
       "Brittani Brin     182.875000         111.000000\n",
       "Calvin North      158.571429          99.285714\n",
       "Coleman Dunmire   194.411765          98.647059\n",
       "Gordon Perrine    185.142857         106.285714\n",
       "Harland Coolidge  182.750000         106.166667\n",
       "Junie Ritenour    179.571429          86.928571\n",
       "Mariah Barberio   170.866667         110.133333\n",
       "Pa Dargan         186.071429         108.285714\n",
       "Phyliss Houk      174.000000          98.812500\n",
       "Williams Camire   177.818182         111.727273"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_df = new_training_df.groupby([\"Trainer\"]).mean()\n",
    "trainer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Membership (Days)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trainer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aldo Byler</th>\n",
       "      <td>3111</td>\n",
       "      <td>1760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barton Stecklein</th>\n",
       "      <td>2267</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bettyann Savory</th>\n",
       "      <td>3584</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blanch Victoria</th>\n",
       "      <td>2654</td>\n",
       "      <td>1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brittani Brin</th>\n",
       "      <td>2926</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calvin North</th>\n",
       "      <td>1110</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coleman Dunmire</th>\n",
       "      <td>3305</td>\n",
       "      <td>1677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gordon Perrine</th>\n",
       "      <td>2592</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harland Coolidge</th>\n",
       "      <td>2193</td>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junie Ritenour</th>\n",
       "      <td>2514</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mariah Barberio</th>\n",
       "      <td>2563</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa Dargan</th>\n",
       "      <td>2605</td>\n",
       "      <td>1516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phyliss Houk</th>\n",
       "      <td>2784</td>\n",
       "      <td>1581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williams Camire</th>\n",
       "      <td>1956</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Weight  Membership (Days)\n",
       "Trainer                                    \n",
       "Aldo Byler          3111               1760\n",
       "Barton Stecklein    2267               1055\n",
       "Bettyann Savory     3584               2047\n",
       "Blanch Victoria     2654               1415\n",
       "Brittani Brin       2926               1776\n",
       "Calvin North        1110                695\n",
       "Coleman Dunmire     3305               1677\n",
       "Gordon Perrine      2592               1488\n",
       "Harland Coolidge    2193               1274\n",
       "Junie Ritenour      2514               1217\n",
       "Mariah Barberio     2563               1652\n",
       "Pa Dargan           2605               1516\n",
       "Phyliss Houk        2784               1581\n",
       "Williams Camire     1956               1229"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using groupby get the average weight and length membership for each trainer.\n",
    "\n",
    "sum_df = pd.DataFrame(\n",
    "    new_training_df.groupby([\"Trainer\"]).sum())\n",
    "sum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 06 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# A seriously gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members\n",
    "training_data = pd.DataFrame({\n",
    "    \"Name\":[\"Gino Walker\",\"Hiedi Wasser\",\"Kerrie Wetzel\",\"Elizabeth Sackett\",\"Jack Mitten\",\"Madalene Wayman\",\"Jamee Horvath\",\"Arlena Reddin\",\"Tula Levan\",\"Teisha Dreier\",\"Leslie Carrier\",\"Arlette Hartson\",\"Romana Merkle\",\"Heath Viviani\",\"Andres Zimmer\",\"Allyson Osman\",\"Yadira Caggiano\",\"Jeanmarie Friedrichs\",\"Leann Ussery\",\"Bee Mom\",\"Pandora Charland\",\"Karena Wooten\",\"Elizabet Albanese\",\"Augusta Borjas\",\"Erma Yadon\",\"Belia Lenser\",\"Karmen Sancho\",\"Edison Mannion\",\"Sonja Hornsby\",\"Morgan Frei\",\"Florencio Murphy\",\"Christoper Hertel\",\"Thalia Stepney\",\"Tarah Argento\",\"Nicol Canfield\",\"Pok Moretti\",\"Barbera Stallings\",\"Muoi Kelso\",\"Cicely Ritz\",\"Sid Demelo\",\"Eura Langan\",\"Vanita An\",\"Frieda Fuhr\",\"Ernest Fitzhenry\",\"Ashlyn Tash\",\"Melodi Mclendon\",\"Rochell Leblanc\",\"Jacqui Reasons\",\"Freeda Mccroy\",\"Vanna Runk\",\"Florinda Milot\",\"Cierra Lecompte\",\"Nancey Kysar\",\"Latasha Dalton\",\"Charlyn Rinaldi\",\"Erline Averett\",\"Mariko Hillary\",\"Rosalyn Trigg\",\"Sherwood Brauer\",\"Hortencia Olesen\",\"Delana Kohut\",\"Geoffrey Mcdade\",\"Iona Delancey\",\"Donnie Read\",\"Cesar Bhatia\",\"Evia Slate\",\"Kaye Hugo\",\"Denise Vento\",\"Lang Kittle\",\"Sherry Whittenberg\",\"Jodi Bracero\",\"Tamera Linneman\",\"Katheryn Koelling\",\"Tonia Shorty\",\"Misha Baxley\",\"Lisbeth Goering\",\"Merle Ladwig\",\"Tammie Omar\",\"Jesusa Avilla\",\"Alda Zabala\",\"Junita Dogan\",\"Jessia Anglin\",\"Peggie Scranton\",\"Dania Clodfelter\",\"Janis Mccarthy\",\"Edmund Galusha\",\"Tonisha Posey\",\"Arvilla Medley\",\"Briana Barbour\",\"Delfina Kiger\",\"Nia Lenig\",\"Ricarda Bulow\",\"Odell Carson\",\"Nydia Clonts\",\"Andree Resendez\",\"Daniela Puma\",\"Sherill Paavola\",\"Gilbert Bloomquist\",\"Shanon Mach\",\"Justin Bangert\",\"Arden Hokanson\",\"Evelyne Bridge\",\"Hee Simek\",\"Ward Deangelis\",\"Jodie Childs\",\"Janis Boehme\",\"Beaulah Glowacki\",\"Denver Stoneham\",\"Tarra Vinton\",\"Deborah Hummell\",\"Ulysses Neil\",\"Kathryn Marques\",\"Rosanna Dake\",\"Gavin Wheat\",\"Tameka Stoke\",\"Janella Clear\",\"Kaye Ciriaco\",\"Suk Bloxham\",\"Gracia Whaley\",\"Philomena Hemingway\",\"Claudette Vaillancourt\",\"Olevia Piche\",\"Trey Chiles\",\"Idalia Scardina\",\"Jenine Tremble\",\"Herbert Krider\",\"Alycia Schrock\",\"Miss Weibel\",\"Pearlene Neidert\",\"Kina Callender\",\"Charlotte Skelley\",\"Theodora Harrigan\",\"Sydney Shreffler\",\"Annamae Trinidad\",\"Tobi Mumme\",\"Rosia Elliot\",\"Debbra Putt\",\"Rena Delosantos\",\"Genna Grennan\",\"Nieves Huf\",\"Berry Lugo\",\"Ayana Verdugo\",\"Joaquin Mazzei\",\"Doris Harmon\",\"Patience Poss\",\"Magaret Zabel\",\"Marylynn Hinojos\",\"Earlene Marcantel\",\"Yuki Evensen\",\"Rema Gay\",\"Delana Haak\",\"Patricia Fetters\",\"Vinnie Elrod\",\"Octavia Bellew\",\"Burma Revard\",\"Lakenya Kato\",\"Vinita Buchner\",\"Sierra Margulies\",\"Shae Funderburg\",\"Jenae Groleau\",\"Louetta Howie\",\"Astrid Duffer\",\"Caron Altizer\",\"Kymberly Amavisca\",\"Mohammad Diedrich\",\"Thora Wrinkle\",\"Bethel Wiemann\",\"Patria Millet\",\"Eldridge Burbach\",\"Alyson Eddie\",\"Zula Hanna\",\"Devin Goodwin\",\"Felipa Kirkwood\",\"Kurtis Kempf\",\"Kasey Lenart\",\"Deena Blankenship\",\"Kandra Wargo\",\"Sherrie Cieslak\",\"Ron Atha\",\"Reggie Barreiro\",\"Daria Saulter\",\"Tandra Eastman\",\"Donnell Lucious\",\"Talisha Rosner\",\"Emiko Bergh\",\"Terresa Launius\",\"Margy Hoobler\",\"Marylou Stelling\",\"Lavonne Justice\",\"Kala Langstaff\",\"China Truett\",\"Louanne Dussault\",\"Thomasena Samaniego\",\"Charlesetta Tarbell\",\"Fatimah Lade\",\"Malisa Cantero\",\"Florencia Litten\",\"Francina Fraise\",\"Patsy London\",\"Deloris Mclaughlin\"],\n",
    "    \"Trainer\":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],\n",
    "    \"Weight\":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],\n",
    "    \"Membership (Days)\":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]\n",
    "})\n",
    "training_data.head()\n",
    "\n",
    "# Convert the membership days into weeks and then add a this data in a new column to the DataFrame.\n",
    "weeks = training_data[\"Membership (Days)\"]/7\n",
    "training_data[\"Membership (Weeks)\"] = weeks\n",
    "\n",
    "training_data.head()\n",
    "\n",
    "# Create a Dataframe that has the Trainer, Weight, and Membership.\n",
    "trainers_data =  training_data[[\"Trainer\", \"Weight\", \"Membership (Days)\", \"Membership (Weeks)\"]]\n",
    "trainers_data\n",
    "\n",
    "# Using groupby get the average weight and length membership for each trainer.\n",
    "\n",
    "trainers_means = trainers_data.groupby([\"Trainer\"]).mean()\n",
    "trainers_means\n",
    "\n",
    "trainers_means.sort_values(by='Membership (Days)', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Turn - 07 - Binning - üë©‚Äçüè´üßë‚Äçüè´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Final Exam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Rami</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Erika</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Shawn</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Nijah</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Robert</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spring</td>\n",
       "      <td>John</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Safira</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spring</td>\n",
       "      <td>An</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Steven</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class    Name  Final Exam\n",
       "0  Spring    Rami          56\n",
       "1  Spring   Erika          71\n",
       "2  Spring   Shawn          85\n",
       "3  Spring   Nijah          67\n",
       "4  Spring  Robert          68\n",
       "5  Spring    John          73\n",
       "6  Spring  Safira          84\n",
       "7  Spring      An          90\n",
       "8  Spring  Steven          73\n",
       "9  Spring   Tomas          84"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Load in file\n",
    "final_exam_scores = \"resources/final_exam_scores.csv\"\n",
    "\n",
    "df = pd.read_csv(final_exam_scores)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Final Exam</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Rami</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Erika</td>\n",
       "      <td>71</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Shawn</td>\n",
       "      <td>85</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Nijah</td>\n",
       "      <td>67</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Robert</td>\n",
       "      <td>68</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spring</td>\n",
       "      <td>John</td>\n",
       "      <td>73</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Safira</td>\n",
       "      <td>84</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spring</td>\n",
       "      <td>An</td>\n",
       "      <td>90</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Steven</td>\n",
       "      <td>73</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Spring</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>84</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class    Name  Final Exam Grade\n",
       "0  Spring    Rami          56     F\n",
       "1  Spring   Erika          71     C\n",
       "2  Spring   Shawn          85     B\n",
       "3  Spring   Nijah          67     D\n",
       "4  Spring  Robert          68     D\n",
       "5  Spring    John          73     C\n",
       "6  Spring  Safira          84     B\n",
       "7  Spring      An          90     A\n",
       "8  Spring  Steven          73     C\n",
       "9  Spring   Tomas          84     B"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the bins in which Data will be held\n",
    "# Bins are 0, 59, 69, 79, 89, 100.   \n",
    "bins = [0, 59, 69, 79, 89, 100]\n",
    "\n",
    "# Create the names for the four bins\n",
    "group_names = [\"F\", \"D\", \"C\", \"B\", \"A\"]\n",
    "\n",
    "df[\"Grade\"] = pd.cut(df[\"Final Exam\"], bins, labels=group_names)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Final Exam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>6.0</td>\n",
       "      <td>57.166667</td>\n",
       "      <td>1.329160</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>6.0</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>3.060501</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>6.0</td>\n",
       "      <td>73.166667</td>\n",
       "      <td>3.125167</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>7.0</td>\n",
       "      <td>84.142857</td>\n",
       "      <td>2.410295</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>5.0</td>\n",
       "      <td>95.600000</td>\n",
       "      <td>3.130495</td>\n",
       "      <td>90.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Final Exam                                                   \n",
       "           count       mean       std   min   25%   50%   75%   max\n",
       "Grade                                                              \n",
       "F            6.0  57.166667  1.329160  56.0  56.0  57.0  58.0  59.0\n",
       "D            6.0  65.833333  3.060501  61.0  64.0  67.5  68.0  68.0\n",
       "C            6.0  73.166667  3.125167  70.0  71.5  73.0  73.0  79.0\n",
       "B            7.0  84.142857  2.410295  80.0  83.5  84.0  85.0  88.0\n",
       "A            5.0  95.600000  3.130495  90.0  97.0  97.0  97.0  97.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the summary statitics of each letter grade. \n",
    "df = df.groupby(\"Grade\")\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Turn - 08 - Binning Ted - üë©‚Äçüéìüë®‚Äçüéì\n",
    "## Binning TED\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Read in the CSV file provided and print it to the screen.\n",
    "\n",
    "* Find the minimum \"views\" and maximum \"views\".\n",
    "\n",
    "* Using the minimum and maximum \"views\" as a reference, create 10 bins in which to slice the data.\n",
    "\n",
    "* Create a new column called \"View Group\" and fill it with the values collected through your slicing.\n",
    "\n",
    "* Group the DataFrame based upon the values within \"View Group\".\n",
    "\n",
    "* Find out how many rows fall into each group before finding the averages for \"comments\", \"duration\", and \"languages\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>47227110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>3200520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>1636292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>1697550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>12005869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1       265  With the same humor and humanity he exuded in ...       977   \n",
       "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3       200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4       593  You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "     event  languages   main_speaker  \\\n",
       "0  TED2006         60   Ken Robinson   \n",
       "1  TED2006         43        Al Gore   \n",
       "2  TED2006         26    David Pogue   \n",
       "3  TED2006         35  Majora Carter   \n",
       "4  TED2006         48   Hans Rosling   \n",
       "\n",
       "                                            name  \\\n",
       "0      Ken Robinson: Do schools kill creativity?   \n",
       "1           Al Gore: Averting the climate crisis   \n",
       "2                  David Pogue: Simplicity sells   \n",
       "3             Majora Carter: Greening the ghetto   \n",
       "4  Hans Rosling: The best stats you've ever seen   \n",
       "\n",
       "                             title     views  \n",
       "0      Do schools kill creativity?  47227110  \n",
       "1      Averting the climate crisis   3200520  \n",
       "2                 Simplicity sells   1636292  \n",
       "3              Greening the ghetto   1697550  \n",
       "4  The best stats you've ever seen  12005869  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Create a path to the csv and read it into a Pandas DataFrame\n",
    "csv_path = \"Resources/ted_talks.csv\"\n",
    "ted_df = pd.read_csv(csv_path)\n",
    "\n",
    "ted_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50443\n",
      "47227110\n"
     ]
    }
   ],
   "source": [
    "# Figure out the minimum and maximum views for a TED Talk\n",
    "print(ted_df[\"views\"].min())\n",
    "print(ted_df[\"views\"].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "      <th>View ranges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>47227110</td>\n",
       "      <td>5mil to 50mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>3200520</td>\n",
       "      <td>3mil to 4mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>1636292</td>\n",
       "      <td>1mil to 2mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>1697550</td>\n",
       "      <td>1mil to 2mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>12005869</td>\n",
       "      <td>5mil to 50mil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1       265  With the same humor and humanity he exuded in ...       977   \n",
       "2       124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3       200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4       593  You've never seen data presented like this. Wi...      1190   \n",
       "\n",
       "     event  languages   main_speaker  \\\n",
       "0  TED2006         60   Ken Robinson   \n",
       "1  TED2006         43        Al Gore   \n",
       "2  TED2006         26    David Pogue   \n",
       "3  TED2006         35  Majora Carter   \n",
       "4  TED2006         48   Hans Rosling   \n",
       "\n",
       "                                            name  \\\n",
       "0      Ken Robinson: Do schools kill creativity?   \n",
       "1           Al Gore: Averting the climate crisis   \n",
       "2                  David Pogue: Simplicity sells   \n",
       "3             Majora Carter: Greening the ghetto   \n",
       "4  Hans Rosling: The best stats you've ever seen   \n",
       "\n",
       "                             title     views    View ranges  \n",
       "0      Do schools kill creativity?  47227110  5mil to 50mil  \n",
       "1      Averting the climate crisis   3200520   3mil to 4mil  \n",
       "2                 Simplicity sells   1636292   1mil to 2mil  \n",
       "3              Greening the ghetto   1697550   1mil to 2mil  \n",
       "4  The best stats you've ever seen  12005869  5mil to 50mil  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bins in which to place values based upon TED Talk views\n",
    "bins = [0, 199999, 399999, 599999, 799999, 999999,\n",
    "        1999999, 2999999, 3999999, 4999999, 50000000]\n",
    "\n",
    "# Create labels for these bins\n",
    "bin_labels = [\"0 to 199k\", \"200k to 399k\", \"400k to 599k\", \"600k to 799k\", \"800k to 999k\",\n",
    "              \"1mil to 2mil\", \"2mil to 3mil\", \"3mil to 4mil\", \"4mil to 5mil\", \"5mil to 50mil\"]\n",
    "\n",
    "# Slice the data and place it into bins\n",
    "# Place the data series into a new column inside of the DataFrame\n",
    "ted_df[\"View ranges\"] = pd.cut(ted_df[\"views\"], bins, labels=bin_labels)\n",
    "ted_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000299A75D0370>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a GroupBy object based upon \"View ranges\"\n",
    "view_group = ted_df.groupby(\"View ranges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1mil to 2mil     1004\n",
       "800k to 999k      339\n",
       "600k to 799k      307\n",
       "2mil to 3mil      239\n",
       "400k to 599k      234\n",
       "200k to 399k      135\n",
       "5mil to 50mil      99\n",
       "3mil to 4mil       93\n",
       "4mil to 5mil       68\n",
       "0 to 199k          32\n",
       "Name: View ranges, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find how many rows fall into each bin\n",
    "ted_df[\"View ranges\"].value_counts()\n",
    "#print(view_group[\"comments\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>duration</th>\n",
       "      <th>languages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>View ranges</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 to 199k</th>\n",
       "      <td>76.937500</td>\n",
       "      <td>898.187500</td>\n",
       "      <td>4.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200k to 399k</th>\n",
       "      <td>81.992593</td>\n",
       "      <td>832.192593</td>\n",
       "      <td>18.785185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400k to 599k</th>\n",
       "      <td>107.162393</td>\n",
       "      <td>870.517094</td>\n",
       "      <td>22.940171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600k to 799k</th>\n",
       "      <td>118.912052</td>\n",
       "      <td>829.039088</td>\n",
       "      <td>24.400651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800k to 999k</th>\n",
       "      <td>119.628319</td>\n",
       "      <td>798.772861</td>\n",
       "      <td>25.678466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mil to 2mil</th>\n",
       "      <td>168.136454</td>\n",
       "      <td>809.899402</td>\n",
       "      <td>27.899402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2mil to 3mil</th>\n",
       "      <td>299.481172</td>\n",
       "      <td>832.430962</td>\n",
       "      <td>32.807531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3mil to 4mil</th>\n",
       "      <td>360.870968</td>\n",
       "      <td>809.505376</td>\n",
       "      <td>34.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4mil to 5mil</th>\n",
       "      <td>507.088235</td>\n",
       "      <td>920.514706</td>\n",
       "      <td>35.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5mil to 50mil</th>\n",
       "      <td>650.393939</td>\n",
       "      <td>884.282828</td>\n",
       "      <td>40.252525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 comments    duration  languages\n",
       "View ranges                                     \n",
       "0 to 199k       76.937500  898.187500   4.062500\n",
       "200k to 399k    81.992593  832.192593  18.785185\n",
       "400k to 599k   107.162393  870.517094  22.940171\n",
       "600k to 799k   118.912052  829.039088  24.400651\n",
       "800k to 999k   119.628319  798.772861  25.678466\n",
       "1mil to 2mil   168.136454  809.899402  27.899402\n",
       "2mil to 3mil   299.481172  832.430962  32.807531\n",
       "3mil to 4mil   360.870968  809.505376  34.258065\n",
       "4mil to 5mil   507.088235  920.514706  35.720588\n",
       "5mil to 50mil  650.393939  884.282828  40.252525"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average of each column within the GroupBy object\n",
    "view_group.mean()\n",
    "#view_group[[\"comments\", \"duration\", \"languages\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><strong>Activity 08 Solution ‚úÖ</strong></summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Create a path to the csv and read it into a Pandas DataFrame\n",
    "csv_path = \"Resources/ted_talks.csv\"\n",
    "ted_df = pd.read_csv(csv_path)\n",
    "\n",
    "ted_df.head()\n",
    "\n",
    "# Figure out the minimum and maximum views for a TED Talk\n",
    "print(ted_df[\"views\"].max())\n",
    "print(ted_df[\"views\"].min())\n",
    "\n",
    "# Create bins in which to place values based upon TED Talk views\n",
    "bins = [0, 199999, 399999, 599999, 799999, 999999,\n",
    "        1999999, 2999999, 3999999, 4999999, 50000000]\n",
    "\n",
    "# Create labels for these bins\n",
    "group_labels = [\"0 to 199k\", \"200k to 399k\", \"400k to 599k\", \"600k to 799k\", \"800k to 999k\", \"1mil to 2mil\",\n",
    "                \"2mil to 3mil\", \"3mil to 4mil\", \"4mil to 5mil\", \"5mil to 50mil\"]\n",
    "\n",
    "# Slice the data and place it into bins\n",
    "pd.cut(ted_df[\"views\"], bins, labels=group_labels).head()\n",
    "\n",
    "# Place the data series into a new column inside of the DataFrame\n",
    "ted_df[\"View Group\"] = pd.cut(ted_df[\"views\"], bins, labels=group_labels)\n",
    "ted_df.head()\n",
    "\n",
    "# Create a GroupBy object based upon \"View Group\"\n",
    "ted_group = ted_df.groupby(\"View Group\")\n",
    "\n",
    "# Find how many rows fall into each bin\n",
    "print(ted_group[\"comments\"].count())\n",
    "\n",
    "# Get the average of each column within the GroupBy object\n",
    "ted_group[[\"comments\", \"duration\", \"languages\"]].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
